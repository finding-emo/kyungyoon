{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "Komoran().pos('했다') # [('하', 'VV'), ('았', 'EP'), ('다', 'EC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(word):\n",
    "    morphtags = komoran.pos(word)\n",
    "    if morphtags[0][1] == 'VA' or morphtags[0][1] == 'VV':\n",
    "        return morphtags[0][0] + '다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "print(konlpy.__version__) # 0.5.1\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "Okt().pos('했다') # [('했다', 'Verb')]\n",
    "Okt().pos('했더라도') # [('했더라도', 'Verb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "print(konlpy.__version__) # 0.4.4\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "for word in ['했다', '했지만', '하면서도', '했던', '하니까']:\n",
    "    print(twitter.pos(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('했', 'Verb'), ('다', 'Eomi')]\n",
    "[('했지만', 'Josa')]\n",
    "[('하면', 'Verb'), ('서도', 'Noun')]\n",
    "[('했', 'Verb'), ('던', 'Eomi')]\n",
    "[('하니', 'Verb'), ('까', 'Eomi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate(stem, eomi):\n",
    "    return stem + eomi\n",
    "\n",
    "conjugate('시작하', '는') # '시작하는'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate(stem, eomi):\n",
    "    cho_s, jung_s, jong_s = decompose(stem[-1])\n",
    "    cho_e, jung_e, jong_e = decompose(eomi[0])\n",
    "    if jong_s == ' ' and jung_e == ' ':\n",
    "        return stem[:-1] + compose(cho_s, jung_s, cho_e) + eomi[1:]\n",
    "    return stem + eomi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_rules = {'란': {('랗', 'ㄴ')}, '했': {('하', '았')}}\n",
    "conju_rules = {('랗', 'ㄴ'): {'란'}, ('하', '았'): {'했'}}\n",
    "\n",
    "def conjugate(stem, eomi, rules):\n",
    "    key = (stem[-1], eomi[0])\n",
    "    surfaces = [stem + eomi]\n",
    "    for conjugation in rules.get(key, {}):\n",
    "        surfaces.append(stem[:-1] + conjugation + eomi[1:])\n",
    "    return surfaces\n",
    "\n",
    "conjugate('파랗', 'ㄴ', conju_rules) # ['파란', '파랗ㄴ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lemmatize(word, i, rules):\n",
    "    key = word[i-1]\n",
    "    lemmas = [(word[:i], word[i:])]\n",
    "    for s, e in rules.get(key, {}):\n",
    "        lemmas.append((word[:i-1] + s, e + word[i:]))\n",
    "    return lemmas\n",
    "\n",
    "_lemmatize('파란', 2, lemma_rules) # [('파', '란'), ('파랗', 'ㄴ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(word, rules, adjectives, verbs, eomis):\n",
    "    lemmas = []\n",
    "    # generate candidates\n",
    "    for i in range(1, len(word) + 1):\n",
    "        lemmas += _lemmatize(word, i, rules)\n",
    "    # check dictionary\n",
    "    lemmas_ = []\n",
    "    for stem, eomi in lemmas:\n",
    "        if not ((stem in adjectives) and (eomi in eomis)):\n",
    "            continue\n",
    "        lemmas_.append((stem, eomi))\n",
    "    return lemmas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_rules = {\n",
    "    '했' : {('하', '았')}\n",
    "    '랬' : {('랗', '았')}\n",
    "    '추운' : {('춥', '은')}\n",
    "    '했다' : {('하', '았다')}\n",
    "    '가우니' : {('갑', '니')}\n",
    "}\n",
    "\n",
    "conju_rules = {\n",
    "    ('하', '았'): {'했'}\n",
    "    ('랗', '았'): {'랬'}\n",
    "    ('춥', '은'): {'추운'}\n",
    "    ('하', '았다'): {'했다'}\n",
    "    ('갑', '니'): {'가우니'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_candidates(word, rules):\n",
    "    max_i = len(word) - 1\n",
    "    candidates = []\n",
    "    for i, c in enumerate(word):\n",
    "        l = word[:i+1]\n",
    "        r = word[i+1:]\n",
    "        l_ = word[:i]\n",
    "        # concatenation\n",
    "        if i < max_i:\n",
    "            candidates.append((l, r))\n",
    "\n",
    "        # 1 syllable conjugation\n",
    "        for stem, eomi in rules.get(c, {}):\n",
    "            for stem, eomi in rules.get(c, {}):\n",
    "                candidates.append((l_ + stem, eomi + r))\n",
    "\n",
    "        # 2 or 3 syllables conjugation\n",
    "        for conj in {word[i:i+2], word[i:i+3]}:\n",
    "            for stem, eomi in rules.get(conj, {}):\n",
    "                candidates.append((l_ + stem, eomi + r[1:]))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sejong_corpus_cleaner.simplier import eojeol_morphtags_to_lr\n",
    "\n",
    "eojeol_morphtags_to_lr('로드무비였다', [('로드', 'NNG'), ('무비', 'NNG'), ('이', 'VCP'), ('었', 'EP'), ('다', 'EC')], separate_xsv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soylemma import extract_rule\n",
    "\n",
    "eojeol = '로드무비였다'\n",
    "lw = '로드무비이'\n",
    "lt = 'Adjective'\n",
    "rw = '었다'\n",
    "rt = 'Eomi'\n",
    "\n",
    "extract_rule(eojeol, lw, lt, rw, rt)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
